{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "seed = 100\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle as pickle \n",
    "import sys\n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_= pd.read_csv('data/customer_preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passengerid', 'trip_total', 'delay_total', 'delay_avg',\n",
       "       'distance_total', 'distance_avg', 'fare_total', 'fare_avg',\n",
       "       'discount_total', 'discount_avg', 'preffered_taximodelid',\n",
       "       'trip_fare_total', 'trip_fare_avg', 'profile_created',\n",
       "       'preffered_payment_method', 'profile_engaged_period', 'pre_booked',\n",
       "       'churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_[['passengerid', 'trip_total', 'delay_total', 'delay_avg',\n",
    "       'distance_total', 'distance_avg', 'fare_total', 'fare_avg',\n",
    "       'discount_total', 'discount_avg', 'preffered_taximodelid',\n",
    "       'trip_fare_total', 'trip_fare_avg',\n",
    "       'preffered_payment_method', 'profile_engaged_period', 'pre_booked',\n",
    "       'churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data=data, columns=['preffered_taximodelid','preffered_payment_method','pre_booked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data[['passengerid', 'trip_total', 'delay_total', 'delay_avg',\n",
    "       'distance_total', 'distance_avg', 'fare_total', 'fare_avg',\n",
    "       'discount_total', 'discount_avg', 'trip_fare_total', 'trip_fare_avg',\n",
    "       'profile_engaged_period', 'preffered_taximodelid_1',\n",
    "       'preffered_taximodelid_2', 'preffered_taximodelid_3',\n",
    "       'preffered_taximodelid_4', 'preffered_taximodelid_10',\n",
    "       'preffered_taximodelid_24', 'preffered_payment_method_1.0',\n",
    "       'preffered_payment_method_2.0', 'preffered_payment_method_3.0',\n",
    "       'preffered_payment_method_5.0', 'preffered_payment_method_7.0',\n",
    "       'pre_booked_0', 'pre_booked_0,1', 'pre_booked_1', 'churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_class = LabelEncoder()\n",
    "label_encoder_class  =label_encoder_class.fit(data[\"churn\"])\n",
    "data[\"churn\"] = label_encoder_class.transform(data[\"churn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,1:27].values  \n",
    "Y=data.iloc[:,27].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3490, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scale = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train = minmax_scale.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "def create_baseline():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(26, input_dim=26, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(estimator, X_train, Y_train, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(50) \n",
    "\n",
    "def create_model(verbose=False):\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "  \n",
    "    if verbose:\n",
    "        print('Network configuration ',neuronCountInEachLayer)\n",
    "    model.add(tf.keras.layers.Dense(neuronCountInEachLayer[0], input_dim=26, activation = activationFuncEachLayer[0], kernel_regularizer=regularizerFunc)) # First Layer\n",
    "    \n",
    "    for x in range(1, depthOfNetwork-1):\n",
    "        \n",
    "        model.add(tf.keras.layers.Dense(neuronCountInEachLayer[x], activation = activationFuncEachLayer[x],kernel_regularizer=regularizerFunc))         # Second layer onwards\n",
    " \n",
    "    model.add(tf.keras.layers.Dense(neuronCountInEachLayer[depthOfNetwork-1], activation = activationFuncEachLayer[depthOfNetwork-1]))  # Output layer\n",
    "    \n",
    "    model.compile(loss = lossFunction , optimizer = 'adam' , metrics = ['accuracy'] ) \n",
    "        \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTheModel(verbose=False):\n",
    "    n_split=5\n",
    "    f1_scores = []\n",
    "    model=create_model(verbose)\n",
    "    for train_index,test_index in StratifiedKFold(n_split).split(X_train, Y_train):      # StratifiedKFold, KFold\n",
    "        x_train,x_test=X[train_index],X[test_index]\n",
    "        y_train,y_test=Y[train_index],Y[test_index]\n",
    "\n",
    "        \n",
    "        model.fit(x_train, y_train,epochs=100, verbose=0)\n",
    "        evaluationMetrics = model.evaluate(x_test,y_test, verbose=0)\n",
    "        \n",
    "        if verbose:\n",
    "            print('Model evaluation ',evaluationMetrics)   # This returns metric values for the evaluation\n",
    "\n",
    "        y_pred = np.where(model.predict(x_test) > 0.5, 1, 0)\n",
    "        f1 = f1_score(y_test, y_pred , average=\"macro\")\n",
    "\n",
    "        if verbose:\n",
    "            print('F1 score is ', f1)\n",
    "        \n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    return np.mean(f1_scores), model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score for 5 K- Fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network configuration  [18, 1]\n",
      "Model evaluation  [0.5408465390331654, 0.7265647]\n",
      "F1 score is  0.7134666827683922\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-bb6d42f74142>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mregularizerFunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNN_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluateTheModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-70a1fe7cef20>\u001b[0m in \u001b[0;36mevaluateTheModel\u001b[1;34m(verbose)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mevaluationMetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;31m# Callbacks batch end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[0mbatch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m     if (self._delta_t_batch > 0. and\n\u001b[0;32m    202\u001b[0m         delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[1;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[0;32m   3495\u001b[0m     \"\"\"\n\u001b[0;32m   3496\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[1;32m-> 3497\u001b[1;33m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[0;32m   3498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3499\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   3403\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3405\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3406\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_median\u001b[1;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[0;32m   3528\u001b[0m             \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3529\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3530\u001b[1;33m         \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 734\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    735\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "depthOfNetwork = 2\n",
    "neuronCountInEachLayer = [18, 1]                                 \n",
    "activationFuncEachLayer = ['sigmoid', 'sigmoid']            \n",
    "lossFunction = 'binary_crossentropy'                                \n",
    "regularizerFunc = tf.keras.regularizers.l2(0)                       \n",
    "\n",
    "f1_score, NN_model = evaluateTheModel(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = minmax_scale.transform(X_test)\n",
    "Y_pred = NN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing neuron count of first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Node count :   3, Mean F1 score :    0.69563\n",
      "'Node count :   4, Mean F1 score :    0.69562\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-a1edec84a0da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mneuronCountInEachLayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'Node count : % 3d, Mean F1 score : % 10.5f\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluateTheModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-c7a2cfe13b24>\u001b[0m in \u001b[0;36mevaluateTheModel\u001b[1;34m(verbose)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mevaluationMetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "depthOfNetwork = 2\n",
    "neuronCountInEachLayer = [15, 1]                                 \n",
    "activationFuncEachLayer = ['sigmoid', 'sigmoid']            \n",
    "lossFunction = 'binary_crossentropy'                                \n",
    "regularizerFunc = tf.keras.regularizers.l2(0)                       \n",
    "\n",
    "for i in range (3, 25):\n",
    "    neuronCountInEachLayer = [i, 1]\n",
    "    print(\"'Node count : % 3d, Mean F1 score : % 10.5f\" %(i, evaluateTheModel())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing no. of hidden layers with constant Neurons(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Hidden layer F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Neurons [ 11], Mean F1 score :    0.84473\n"
     ]
    }
   ],
   "source": [
    "depthOfNetwork = 2\n",
    "neuronCountInEachLayer = [11, 1]                                 \n",
    "activationFuncEachLayer = ['sigmoid', 'sigmoid']           \n",
    "lossFunction = 'binary_crossentropy'                             \n",
    "regularizerFunc = tf.keras.regularizers.l2(0)                     \n",
    "print(\"'Neurons [% 3d], Mean F1 score : % 10.5f\" %(11, evaluateTheModel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Hidden layer F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Neurons [ 11,  11], Mean F1 score :    0.84051\n"
     ]
    }
   ],
   "source": [
    "depthOfNetwork = 3\n",
    "neuronCountInEachLayer = [11,11, 1]                                \n",
    "activationFuncEachLayer = ['sigmoid', 'sigmoid', 'sigmoid']           \n",
    "lossFunction = 'binary_crossentropy'                               \n",
    "regularizerFunc = tf.keras.regularizers.l2(0)\n",
    "print(\"'Neurons [% 3d, % 3d], Mean F1 score : % 10.5f\" %(11,11, evaluateTheModel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Hidden layer F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Neurons [ 11,  11, 11], Mean F1 score :    0.84500\n"
     ]
    }
   ],
   "source": [
    "depthOfNetwork = 4\n",
    "neuronCountInEachLayer = [11,11,11, 1]                                \n",
    "activationFuncEachLayer = ['sigmoid', 'sigmoid', 'sigmoid','sigmoid']           \n",
    "lossFunction = 'binary_crossentropy'                               \n",
    "regularizerFunc = tf.keras.regularizers.l2(0)\n",
    "print(\"'Neurons [% 3d, % 3d,% 3d], Mean F1 score : % 10.5f\" %(11,11,11, evaluateTheModel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Hidden layer F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Neurons [ 15,  15, 15, 15], Mean F1 score :    0.84403\n"
     ]
    }
   ],
   "source": [
    "depthOfNetwork = 5\n",
    "neuronCountInEachLayer = [11,11,11,11, 1]                                 \n",
    "activationFuncEachLayer = ['sigmoid', 'sigmoid', 'sigmoid','sigmoid','sigmoid']           \n",
    "lossFunction = 'binary_crossentropy'                               \n",
    "regularizerFunc = tf.keras.regularizers.l2(0)\n",
    "print(\"'Neurons [% 3d, % 3d,% 3d,% 3d], Mean F1 score : % 10.5f\" %(11,11,11,11, evaluateTheModel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Hidden layer F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Neurons [ 11,  11, 11, 11, 11], Mean F1 score :    0.85213\n"
     ]
    }
   ],
   "source": [
    "depthOfNetwork = 6\n",
    "neuronCountInEachLayer = [11,11,11,11,11,1]                                \n",
    "activationFuncEachLayer = ['sigmoid', 'sigmoid', 'sigmoid','sigmoid','sigmoid','sigmoid']         \n",
    "lossFunction = 'binary_crossentropy'                               \n",
    "regularizerFunc = tf.keras.regularizers.l2(0)\n",
    "print(\"'Neurons [% 3d, % 3d,% 3d,% 3d,% 3d], Mean F1 score : % 10.5f\" %(11,11,11,11,11, evaluateTheModel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing different Error functions with 1 hidden layers with consatant Neurons(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_crossentropy\n",
      "Neurons [ 11], Mean F1 score :    0.84896\n",
      "mean_squared_error\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Neurons [ 11], Mean F1 score :    0.84606\n",
      "mean_squared_logarithmic_error\n",
      "Neurons [ 11], Mean F1 score :    0.84550\n"
     ]
    }
   ],
   "source": [
    "depthOfNetwork = 2\n",
    "neuronCountInEachLayer = [11, 1]                               \n",
    "activationFuncEachLayer = ['sigmoid', 'sigmoid']           \n",
    "lossFunction_list = ['binary_crossentropy','mean_squared_error','mean_squared_logarithmic_error']                                # try values binary_crossentropy, mean_squared_error,mean_squared_logarithmic_error\n",
    "regularizerFunc = tf.keras.regularizers.l2(0)                      \n",
    "for each in lossFunction_list:\n",
    "    lossFunction = each\n",
    "    print(each)\n",
    "    print(\"Neurons [% 3d], Mean F1 score : % 10.5f\" %(11,evaluateTheModel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing different activation functions with 1 hidden layers with consatant Neurons(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Neurons [ 11], Mean F1 score :    0.84088\n",
      "'Neurons [ 11], Mean F1 score :    0.84993\n",
      "'Neurons [ 11], Mean F1 score :    0.85080\n"
     ]
    }
   ],
   "source": [
    "depthOfNetwork = 2\n",
    "neuronCountInEachLayer = [11, 1]                                \n",
    "activationFuncEachLayer_list = ['relu','tanh', 'sigmoid']           \n",
    "lossFunction = 'binary_crossentropy'                               \n",
    "regularizerFunc = tf.keras.regularizers.l2(0)                      \n",
    "for each in activationFuncEachLayer_list:\n",
    "    activationFuncEachLayer = [each,'sigmoid']\n",
    "    print(\"'Neurons [% 3d], Mean F1 score : % 10.5f\" %(11, evaluateTheModel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 regularization with different lambda values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Regularizor : l1 with lambda :    0.00001 , Mean F1 score :    0.84077\n",
      "'Regularizor : l1 with lambda :    0.00010 , Mean F1 score :    0.85206\n",
      "'Regularizor : l1 with lambda :    0.00100 , Mean F1 score :    0.84551\n",
      "'Regularizor : l1 with lambda :    0.01000 , Mean F1 score :    0.85143\n",
      "'Regularizor : l1 with lambda :    0.10000 , Mean F1 score :    0.35694\n",
      "'Regularizor : l1 with lambda :    1.00000 , Mean F1 score :    0.35694\n",
      "'Regularizor : l1 with lambda :   10.00000 , Mean F1 score :    0.35694\n"
     ]
    }
   ],
   "source": [
    "depthOfNetwork = 2\n",
    "neuronCountInEachLayer = [11,1]                               \n",
    "activationFuncEachLayer = ['sigmoid', 'sigmoid']           \n",
    "lossFunction = 'binary_crossentropy'                                \n",
    "regularizerFunc = tf.keras.regularizers.l1(0)                      \n",
    "\n",
    "for i in range(-5,2):\n",
    "    regularizerFunc = tf.keras.regularizers.l1(10**i)\n",
    "    print(\"'Regularizor : l1 with lambda : % 10.5f , Mean F1 score : % 10.5f\" %(10**i, evaluateTheModel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 regularization with different lambda values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "'Regularizor : l2 with lambda :    0.00001 , Mean F1 score :    0.85183\n",
      "'Regularizor : l2 with lambda :    0.00010 , Mean F1 score :    0.85021\n",
      "'Regularizor : l2 with lambda :    0.00100 , Mean F1 score :    0.84533\n",
      "'Regularizor : l2 with lambda :    0.01000 , Mean F1 score :    0.84246\n",
      "'Regularizor : l2 with lambda :    0.10000 , Mean F1 score :    0.44913\n",
      "'Regularizor : l2 with lambda :    1.00000 , Mean F1 score :    0.35694\n",
      "'Regularizor : l2 with lambda :   10.00000 , Mean F1 score :    0.35694\n"
     ]
    }
   ],
   "source": [
    "depthOfNetwork = 2\n",
    "neuronCountInEachLayer = [11,1]                                \n",
    "activationFuncEachLayer = ['sigmoid', 'sigmoid']           \n",
    "lossFunction = 'binary_crossentropy'                                \n",
    "regularizerFunc = tf.keras.regularizers.l2(0)                      \n",
    "\n",
    "for i in range(-5,2):\n",
    "    regularizerFunc = tf.keras.regularizers.l2(10**i)\n",
    "    print(\"'Regularizor : l2 with lambda : % 10.5f , Mean F1 score : % 10.5f\" %(10**i, evaluateTheModel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
